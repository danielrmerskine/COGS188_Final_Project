{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Family_History</th>\n",
       "      <th>Race_African_Ancestry</th>\n",
       "      <th>PSA_Level</th>\n",
       "      <th>DRE_Result</th>\n",
       "      <th>Biopsy_Result</th>\n",
       "      <th>Difficulty_Urinating</th>\n",
       "      <th>Weak_Urine_Flow</th>\n",
       "      <th>Blood_in_Urine</th>\n",
       "      <th>...</th>\n",
       "      <th>Alcohol_Consumption</th>\n",
       "      <th>Hypertension</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Cholesterol_Level</th>\n",
       "      <th>Screening_Age</th>\n",
       "      <th>Follow_Up_Required</th>\n",
       "      <th>Prostate_Volume</th>\n",
       "      <th>Genetic_Risk_Factors</th>\n",
       "      <th>Previous_Cancer_History</th>\n",
       "      <th>Early_Detection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5.07</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Benign</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Normal</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>46.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10.24</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>Low</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>High</td>\n",
       "      <td>65</td>\n",
       "      <td>No</td>\n",
       "      <td>78.2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>13.79</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Benign</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>Low</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Normal</td>\n",
       "      <td>61</td>\n",
       "      <td>No</td>\n",
       "      <td>21.1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>82</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>8.03</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>Benign</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>Low</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Normal</td>\n",
       "      <td>47</td>\n",
       "      <td>Yes</td>\n",
       "      <td>79.9</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>47</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1.89</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Normal</td>\n",
       "      <td>72</td>\n",
       "      <td>No</td>\n",
       "      <td>32.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27940</th>\n",
       "      <td>27941</td>\n",
       "      <td>49</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>9.35</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Benign</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>High</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Normal</td>\n",
       "      <td>42</td>\n",
       "      <td>No</td>\n",
       "      <td>47.9</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27941</th>\n",
       "      <td>27942</td>\n",
       "      <td>84</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1.24</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Benign</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Normal</td>\n",
       "      <td>47</td>\n",
       "      <td>Yes</td>\n",
       "      <td>55.3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27942</th>\n",
       "      <td>27943</td>\n",
       "      <td>69</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>5.01</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>Low</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Normal</td>\n",
       "      <td>44</td>\n",
       "      <td>No</td>\n",
       "      <td>47.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27943</th>\n",
       "      <td>27944</td>\n",
       "      <td>50</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>5.71</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Normal</td>\n",
       "      <td>67</td>\n",
       "      <td>No</td>\n",
       "      <td>24.2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27944</th>\n",
       "      <td>27945</td>\n",
       "      <td>73</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1.74</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>Benign</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Normal</td>\n",
       "      <td>42</td>\n",
       "      <td>No</td>\n",
       "      <td>36.9</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27945 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Patient_ID  Age Family_History Race_African_Ancestry  PSA_Level  \\\n",
       "0               1   78             No                   Yes       5.07   \n",
       "1               2   68             No                   Yes      10.24   \n",
       "2               3   54             No                    No      13.79   \n",
       "3               4   82             No                    No       8.03   \n",
       "4               5   47            Yes                    No       1.89   \n",
       "...           ...  ...            ...                   ...        ...   \n",
       "27940       27941   49            Yes                    No       9.35   \n",
       "27941       27942   84            Yes                    No       1.24   \n",
       "27942       27943   69             No                    No       5.01   \n",
       "27943       27944   50             No                    No       5.71   \n",
       "27944       27945   73             No                    No       1.74   \n",
       "\n",
       "      DRE_Result Biopsy_Result Difficulty_Urinating Weak_Urine_Flow  \\\n",
       "0         Normal        Benign                   No              No   \n",
       "1         Normal        Benign                  Yes              No   \n",
       "2         Normal        Benign                   No              No   \n",
       "3       Abnormal        Benign                   No              No   \n",
       "4         Normal     Malignant                  Yes             Yes   \n",
       "...          ...           ...                  ...             ...   \n",
       "27940     Normal        Benign                   No              No   \n",
       "27941     Normal        Benign                   No              No   \n",
       "27942   Abnormal     Malignant                   No              No   \n",
       "27943     Normal        Benign                  Yes             Yes   \n",
       "27944   Abnormal        Benign                   No             Yes   \n",
       "\n",
       "      Blood_in_Urine  ... Alcohol_Consumption Hypertension Diabetes  \\\n",
       "0                 No  ...            Moderate           No       No   \n",
       "1                 No  ...                 Low           No       No   \n",
       "2                 No  ...                 Low           No       No   \n",
       "3                 No  ...                 Low           No       No   \n",
       "4                 No  ...            Moderate          Yes       No   \n",
       "...              ...  ...                 ...          ...      ...   \n",
       "27940             No  ...                High          Yes      Yes   \n",
       "27941             No  ...            Moderate          Yes       No   \n",
       "27942             No  ...                 Low          Yes       No   \n",
       "27943             No  ...            Moderate          Yes      Yes   \n",
       "27944             No  ...            Moderate           No      Yes   \n",
       "\n",
       "      Cholesterol_Level Screening_Age Follow_Up_Required Prostate_Volume  \\\n",
       "0                Normal            45                 No            46.0   \n",
       "1                  High            65                 No            78.2   \n",
       "2                Normal            61                 No            21.1   \n",
       "3                Normal            47                Yes            79.9   \n",
       "4                Normal            72                 No            32.0   \n",
       "...                 ...           ...                ...             ...   \n",
       "27940            Normal            42                 No            47.9   \n",
       "27941            Normal            47                Yes            55.3   \n",
       "27942            Normal            44                 No            47.0   \n",
       "27943            Normal            67                 No            24.2   \n",
       "27944            Normal            42                 No            36.9   \n",
       "\n",
       "      Genetic_Risk_Factors  Previous_Cancer_History Early_Detection  \n",
       "0                       No                       No             Yes  \n",
       "1                       No                       No             Yes  \n",
       "2                       No                       No             Yes  \n",
       "3                       No                      Yes             Yes  \n",
       "4                       No                       No             Yes  \n",
       "...                    ...                      ...             ...  \n",
       "27940                   No                       No             Yes  \n",
       "27941                   No                       No             Yes  \n",
       "27942                   No                      Yes             Yes  \n",
       "27943                   No                       No             Yes  \n",
       "27944                  Yes                       No             Yes  \n",
       "\n",
       "[27945 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"prostate_cancer_prediction.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>PSA_Level</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Screening_Age</th>\n",
       "      <th>Prostate_Volume</th>\n",
       "      <th>Family_History_Yes</th>\n",
       "      <th>Race_African_Ancestry_Yes</th>\n",
       "      <th>DRE_Result_Normal</th>\n",
       "      <th>Difficulty_Urinating_Yes</th>\n",
       "      <th>Weak_Urine_Flow_Yes</th>\n",
       "      <th>...</th>\n",
       "      <th>Smoking_History_Yes</th>\n",
       "      <th>Alcohol_Consumption_Low</th>\n",
       "      <th>Alcohol_Consumption_Moderate</th>\n",
       "      <th>Hypertension_Yes</th>\n",
       "      <th>Diabetes_Yes</th>\n",
       "      <th>Cholesterol_Level_Normal</th>\n",
       "      <th>Follow_Up_Required_Yes</th>\n",
       "      <th>Genetic_Risk_Factors_Yes</th>\n",
       "      <th>Previous_Cancer_History_Yes</th>\n",
       "      <th>Early_Detection_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.939988</td>\n",
       "      <td>-0.642309</td>\n",
       "      <td>-0.861585</td>\n",
       "      <td>-1.176363</td>\n",
       "      <td>-0.093872</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.245761</td>\n",
       "      <td>0.596033</td>\n",
       "      <td>-1.250276</td>\n",
       "      <td>0.800335</td>\n",
       "      <td>1.627690</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.726158</td>\n",
       "      <td>1.446345</td>\n",
       "      <td>-1.229818</td>\n",
       "      <td>0.404995</td>\n",
       "      <td>-1.425141</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.217679</td>\n",
       "      <td>0.066684</td>\n",
       "      <td>0.386317</td>\n",
       "      <td>-0.978694</td>\n",
       "      <td>1.718580</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.212117</td>\n",
       "      <td>-1.403997</td>\n",
       "      <td>0.734093</td>\n",
       "      <td>1.492179</td>\n",
       "      <td>-0.842377</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27940</th>\n",
       "      <td>-1.073272</td>\n",
       "      <td>0.382856</td>\n",
       "      <td>0.488604</td>\n",
       "      <td>-1.472868</td>\n",
       "      <td>0.007711</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27941</th>\n",
       "      <td>1.356525</td>\n",
       "      <td>-1.559688</td>\n",
       "      <td>-0.984330</td>\n",
       "      <td>-0.978694</td>\n",
       "      <td>0.403350</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27942</th>\n",
       "      <td>0.315184</td>\n",
       "      <td>-0.656680</td>\n",
       "      <td>0.140828</td>\n",
       "      <td>-1.275198</td>\n",
       "      <td>-0.040407</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27943</th>\n",
       "      <td>-1.003849</td>\n",
       "      <td>-0.489013</td>\n",
       "      <td>-1.086617</td>\n",
       "      <td>0.998004</td>\n",
       "      <td>-1.259401</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27944</th>\n",
       "      <td>0.592875</td>\n",
       "      <td>-1.439926</td>\n",
       "      <td>-1.250276</td>\n",
       "      <td>-1.472868</td>\n",
       "      <td>-0.580400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27945 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Age  PSA_Level       BMI  Screening_Age  Prostate_Volume  \\\n",
       "0      0.939988  -0.642309 -0.861585      -1.176363        -0.093872   \n",
       "1      0.245761   0.596033 -1.250276       0.800335         1.627690   \n",
       "2     -0.726158   1.446345 -1.229818       0.404995        -1.425141   \n",
       "3      1.217679   0.066684  0.386317      -0.978694         1.718580   \n",
       "4     -1.212117  -1.403997  0.734093       1.492179        -0.842377   \n",
       "...         ...        ...       ...            ...              ...   \n",
       "27940 -1.073272   0.382856  0.488604      -1.472868         0.007711   \n",
       "27941  1.356525  -1.559688 -0.984330      -0.978694         0.403350   \n",
       "27942  0.315184  -0.656680  0.140828      -1.275198        -0.040407   \n",
       "27943 -1.003849  -0.489013 -1.086617       0.998004        -1.259401   \n",
       "27944  0.592875  -1.439926 -1.250276      -1.472868        -0.580400   \n",
       "\n",
       "       Family_History_Yes  Race_African_Ancestry_Yes  DRE_Result_Normal  \\\n",
       "0                       0                          1                  1   \n",
       "1                       0                          1                  1   \n",
       "2                       0                          0                  1   \n",
       "3                       0                          0                  0   \n",
       "4                       1                          0                  1   \n",
       "...                   ...                        ...                ...   \n",
       "27940                   1                          0                  1   \n",
       "27941                   1                          0                  1   \n",
       "27942                   0                          0                  0   \n",
       "27943                   0                          0                  1   \n",
       "27944                   0                          0                  0   \n",
       "\n",
       "       Difficulty_Urinating_Yes  Weak_Urine_Flow_Yes  ...  \\\n",
       "0                             0                    0  ...   \n",
       "1                             1                    0  ...   \n",
       "2                             0                    0  ...   \n",
       "3                             0                    0  ...   \n",
       "4                             1                    1  ...   \n",
       "...                         ...                  ...  ...   \n",
       "27940                         0                    0  ...   \n",
       "27941                         0                    0  ...   \n",
       "27942                         0                    0  ...   \n",
       "27943                         1                    1  ...   \n",
       "27944                         0                    1  ...   \n",
       "\n",
       "       Smoking_History_Yes  Alcohol_Consumption_Low  \\\n",
       "0                        1                        0   \n",
       "1                        0                        1   \n",
       "2                        1                        1   \n",
       "3                        0                        1   \n",
       "4                        0                        0   \n",
       "...                    ...                      ...   \n",
       "27940                    1                        0   \n",
       "27941                    0                        0   \n",
       "27942                    0                        1   \n",
       "27943                    0                        0   \n",
       "27944                    1                        0   \n",
       "\n",
       "       Alcohol_Consumption_Moderate  Hypertension_Yes  Diabetes_Yes  \\\n",
       "0                                 1                 0             0   \n",
       "1                                 0                 0             0   \n",
       "2                                 0                 0             0   \n",
       "3                                 0                 0             0   \n",
       "4                                 1                 1             0   \n",
       "...                             ...               ...           ...   \n",
       "27940                             0                 1             1   \n",
       "27941                             1                 1             0   \n",
       "27942                             0                 1             0   \n",
       "27943                             1                 1             1   \n",
       "27944                             1                 0             1   \n",
       "\n",
       "       Cholesterol_Level_Normal  Follow_Up_Required_Yes  \\\n",
       "0                             1                       0   \n",
       "1                             0                       0   \n",
       "2                             1                       0   \n",
       "3                             1                       1   \n",
       "4                             1                       0   \n",
       "...                         ...                     ...   \n",
       "27940                         1                       0   \n",
       "27941                         1                       1   \n",
       "27942                         1                       0   \n",
       "27943                         1                       0   \n",
       "27944                         1                       0   \n",
       "\n",
       "       Genetic_Risk_Factors_Yes  Previous_Cancer_History_Yes  \\\n",
       "0                             0                            0   \n",
       "1                             0                            0   \n",
       "2                             0                            0   \n",
       "3                             0                            1   \n",
       "4                             0                            0   \n",
       "...                         ...                          ...   \n",
       "27940                         0                            0   \n",
       "27941                         0                            0   \n",
       "27942                         0                            1   \n",
       "27943                         0                            0   \n",
       "27944                         1                            0   \n",
       "\n",
       "       Early_Detection_Yes  \n",
       "0                        1  \n",
       "1                        1  \n",
       "2                        1  \n",
       "3                        1  \n",
       "4                        1  \n",
       "...                    ...  \n",
       "27940                    1  \n",
       "27941                    1  \n",
       "27942                    1  \n",
       "27943                    1  \n",
       "27944                    1  \n",
       "\n",
       "[27945 rows x 34 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Drop non-predictive features\n",
    "data.drop('Patient_ID', axis=1, inplace=True)\n",
    "\n",
    "# Encode the target variable (Biopsy_Result)\n",
    "data['Biopsy_Result'] = data['Biopsy_Result'].map({'Benign': 0, 'Malignant': 1})\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "categorical_cols = data.select_dtypes(include='object').columns\n",
    "encoder = OneHotEncoder(drop='first', dtype=int)\n",
    "encoded_data = pd.DataFrame(encoder.fit_transform(data[categorical_cols]).toarray(),\n",
    "                            columns=encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "# Drop original categorical columns and combine encoded data\n",
    "data.drop(categorical_cols, axis=1, inplace=True)\n",
    "data = pd.concat([data, encoded_data], axis=1)\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_cols = ['Age', 'PSA_Level', 'BMI', 'Screening_Age', 'Prostate_Volume']\n",
    "scaler = StandardScaler()\n",
    "data[numerical_cols] = scaler.fit_transform(data[numerical_cols])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X = data.drop('Biopsy_Result', axis=1)\n",
    "y = data['Biopsy_Result']\n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check for CUDA\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Split data into training, validation, and testing sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_tensor, y_train_tensor = torch.tensor(X_train.values, dtype=torch.float32).to(device), torch.tensor(y_train.values, dtype=torch.float32).to(device)\n",
    "X_val_tensor, y_val_tensor = torch.tensor(X_val.values, dtype=torch.float32).to(device), torch.tensor(y_val.values, dtype=torch.float32).to(device)\n",
    "X_test_tensor, y_test_tensor = torch.tensor(X_test.values, dtype=torch.float32).to(device), torch.tensor(y_test.values, dtype=torch.float32).to(device)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "model = NeuralNetwork(X_train.shape[1]).to(device)\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "def train(model, train_loader, val_loader, criterion, optimizer, num_epochs=100, initial_lr=0.004, patience=10):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs).squeeze() \n",
    "\n",
    "            loss = criterion(outputs, targets) \n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # Validation step\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs).squeeze()\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "\n",
    "    # Plot training and validation loss\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(range(len(train_losses)), train_losses, label=\"Train Loss\")\n",
    "    plt.plot(range(len(val_losses)), val_losses, label=\"Validation Loss\", linestyle=\"dashed\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Training and Validation Loss Over Epochs\")\n",
    "    plt.show()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Evaluation loop\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in loader:\n",
    "            outputs = model(X_batch).squeeze()\n",
    "            predictions = (outputs >= 0.5).float()\n",
    "            correct += (predictions == y_batch).sum().item()\n",
    "            total += y_batch.size(0)\n",
    "    accuracy = correct / total\n",
    "    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.6041, Val Loss: 0.6134\n",
      "Epoch 2/100, Train Loss: 0.6040, Val Loss: 0.6134\n",
      "Epoch 3/100, Train Loss: 0.6046, Val Loss: 0.6134\n",
      "Epoch 4/100, Train Loss: 0.6045, Val Loss: 0.6134\n",
      "Epoch 5/100, Train Loss: 0.6042, Val Loss: 0.6134\n",
      "Epoch 6/100, Train Loss: 0.6039, Val Loss: 0.6134\n",
      "Epoch 7/100, Train Loss: 0.6044, Val Loss: 0.6134\n",
      "Epoch 8/100, Train Loss: 0.6041, Val Loss: 0.6134\n",
      "Epoch 9/100, Train Loss: 0.6044, Val Loss: 0.6134\n",
      "Epoch 10/100, Train Loss: 0.6043, Val Loss: 0.6134\n",
      "Epoch 11/100, Train Loss: 0.6041, Val Loss: 0.6134\n",
      "Epoch 12/100, Train Loss: 0.6047, Val Loss: 0.6134\n",
      "Epoch 13/100, Train Loss: 0.6046, Val Loss: 0.6134\n",
      "Epoch 14/100, Train Loss: 0.6040, Val Loss: 0.6134\n",
      "Epoch 15/100, Train Loss: 0.6046, Val Loss: 0.6134\n",
      "Epoch 16/100, Train Loss: 0.6041, Val Loss: 0.6134\n",
      "Epoch 17/100, Train Loss: 0.6042, Val Loss: 0.6134\n",
      "Epoch 18/100, Train Loss: 0.6046, Val Loss: 0.6134\n",
      "Epoch 19/100, Train Loss: 0.6046, Val Loss: 0.6134\n",
      "Epoch 20/100, Train Loss: 0.6044, Val Loss: 0.6134\n",
      "Epoch 21/100, Train Loss: 0.6044, Val Loss: 0.6134\n",
      "Epoch 22/100, Train Loss: 0.6044, Val Loss: 0.6134\n",
      "Epoch 23/100, Train Loss: 0.6043, Val Loss: 0.6134\n",
      "Epoch 24/100, Train Loss: 0.6046, Val Loss: 0.6134\n",
      "Epoch 25/100, Train Loss: 0.6046, Val Loss: 0.6134\n",
      "Epoch 26/100, Train Loss: 0.6045, Val Loss: 0.6134\n",
      "Epoch 27/100, Train Loss: 0.6043, Val Loss: 0.6134\n",
      "Epoch 28/100, Train Loss: 0.6048, Val Loss: 0.6134\n",
      "Epoch 29/100, Train Loss: 0.6039, Val Loss: 0.6134\n",
      "Epoch 30/100, Train Loss: 0.6041, Val Loss: 0.6134\n",
      "Epoch 31/100, Train Loss: 0.6042, Val Loss: 0.6134\n",
      "Epoch 32/100, Train Loss: 0.6041, Val Loss: 0.6134\n",
      "Epoch 33/100, Train Loss: 0.6042, Val Loss: 0.6134\n",
      "Epoch 34/100, Train Loss: 0.6042, Val Loss: 0.6134\n",
      "Epoch 35/100, Train Loss: 0.6041, Val Loss: 0.6134\n",
      "Epoch 36/100, Train Loss: 0.6048, Val Loss: 0.6134\n",
      "Epoch 37/100, Train Loss: 0.6044, Val Loss: 0.6134\n",
      "Epoch 38/100, Train Loss: 0.6042, Val Loss: 0.6134\n",
      "Epoch 39/100, Train Loss: 0.6045, Val Loss: 0.6134\n",
      "Epoch 40/100, Train Loss: 0.6045, Val Loss: 0.6134\n",
      "Epoch 41/100, Train Loss: 0.6038, Val Loss: 0.6134\n",
      "Epoch 42/100, Train Loss: 0.6045, Val Loss: 0.6134\n",
      "Epoch 43/100, Train Loss: 0.6043, Val Loss: 0.6134\n",
      "Epoch 44/100, Train Loss: 0.6046, Val Loss: 0.6134\n",
      "Epoch 45/100, Train Loss: 0.6048, Val Loss: 0.6134\n",
      "Epoch 46/100, Train Loss: 0.6040, Val Loss: 0.6134\n",
      "Epoch 47/100, Train Loss: 0.6041, Val Loss: 0.6134\n",
      "Epoch 48/100, Train Loss: 0.6047, Val Loss: 0.6134\n",
      "Epoch 49/100, Train Loss: 0.6043, Val Loss: 0.6134\n",
      "Epoch 50/100, Train Loss: 0.6051, Val Loss: 0.6134\n",
      "Epoch 51/100, Train Loss: 0.6044, Val Loss: 0.6134\n",
      "Epoch 52/100, Train Loss: 0.6044, Val Loss: 0.6134\n",
      "Epoch 53/100, Train Loss: 0.6043, Val Loss: 0.6134\n",
      "Epoch 54/100, Train Loss: 0.6043, Val Loss: 0.6134\n",
      "Epoch 55/100, Train Loss: 0.6041, Val Loss: 0.6134\n",
      "Epoch 56/100, Train Loss: 0.6049, Val Loss: 0.6134\n",
      "Epoch 57/100, Train Loss: 0.6044, Val Loss: 0.6134\n",
      "Epoch 58/100, Train Loss: 0.6040, Val Loss: 0.6134\n",
      "Epoch 59/100, Train Loss: 0.6043, Val Loss: 0.6134\n",
      "Epoch 60/100, Train Loss: 0.6045, Val Loss: 0.6134\n",
      "Epoch 61/100, Train Loss: 0.6048, Val Loss: 0.6134\n",
      "Epoch 62/100, Train Loss: 0.6042, Val Loss: 0.6134\n",
      "Epoch 63/100, Train Loss: 0.6043, Val Loss: 0.6134\n",
      "Epoch 64/100, Train Loss: 0.6044, Val Loss: 0.6134\n",
      "Epoch 65/100, Train Loss: 0.6043, Val Loss: 0.6134\n",
      "Epoch 66/100, Train Loss: 0.6043, Val Loss: 0.6134\n",
      "Epoch 67/100, Train Loss: 0.6048, Val Loss: 0.6134\n",
      "Epoch 68/100, Train Loss: 0.6045, Val Loss: 0.6134\n",
      "Epoch 69/100, Train Loss: 0.6045, Val Loss: 0.6134\n",
      "Epoch 70/100, Train Loss: 0.6046, Val Loss: 0.6134\n",
      "Epoch 71/100, Train Loss: 0.6045, Val Loss: 0.6134\n",
      "Epoch 72/100, Train Loss: 0.6042, Val Loss: 0.6134\n",
      "Epoch 73/100, Train Loss: 0.6040, Val Loss: 0.6134\n",
      "Epoch 74/100, Train Loss: 0.6040, Val Loss: 0.6134\n",
      "Epoch 75/100, Train Loss: 0.6044, Val Loss: 0.6134\n",
      "Epoch 76/100, Train Loss: 0.6042, Val Loss: 0.6134\n",
      "Epoch 77/100, Train Loss: 0.6042, Val Loss: 0.6134\n",
      "Epoch 78/100, Train Loss: 0.6043, Val Loss: 0.6134\n",
      "Epoch 79/100, Train Loss: 0.6045, Val Loss: 0.6134\n",
      "Epoch 80/100, Train Loss: 0.6048, Val Loss: 0.6134\n",
      "Epoch 81/100, Train Loss: 0.6047, Val Loss: 0.6134\n",
      "Epoch 82/100, Train Loss: 0.6046, Val Loss: 0.6134\n",
      "Epoch 83/100, Train Loss: 0.6046, Val Loss: 0.6134\n",
      "Epoch 84/100, Train Loss: 0.6045, Val Loss: 0.6134\n",
      "Epoch 85/100, Train Loss: 0.6041, Val Loss: 0.6134\n",
      "Epoch 86/100, Train Loss: 0.6040, Val Loss: 0.6134\n",
      "Epoch 87/100, Train Loss: 0.6044, Val Loss: 0.6134\n",
      "Epoch 88/100, Train Loss: 0.6041, Val Loss: 0.6134\n",
      "Epoch 89/100, Train Loss: 0.6044, Val Loss: 0.6134\n",
      "Epoch 90/100, Train Loss: 0.6045, Val Loss: 0.6134\n",
      "Epoch 91/100, Train Loss: 0.6045, Val Loss: 0.6134\n",
      "Epoch 92/100, Train Loss: 0.6044, Val Loss: 0.6134\n",
      "Epoch 93/100, Train Loss: 0.6039, Val Loss: 0.6134\n",
      "Epoch 94/100, Train Loss: 0.6043, Val Loss: 0.6134\n",
      "Epoch 95/100, Train Loss: 0.6044, Val Loss: 0.6134\n",
      "Epoch 96/100, Train Loss: 0.6047, Val Loss: 0.6134\n",
      "Epoch 97/100, Train Loss: 0.6044, Val Loss: 0.6134\n",
      "Epoch 98/100, Train Loss: 0.6044, Val Loss: 0.6134\n",
      "Epoch 99/100, Train Loss: 0.6042, Val Loss: 0.6134\n",
      "Epoch 100/100, Train Loss: 0.6045, Val Loss: 0.6134\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train and evaluate the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m evaluate(model, test_loader)\n",
      "Cell \u001b[1;32mIn[7], line 53\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, val_loader, criterion, optimizer, num_epochs, initial_lr, patience)\u001b[0m\n\u001b[0;32m     49\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep(avg_val_loss)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_train_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_val_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 53\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbest_model.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Plot training and validation loss\u001b[39;00m\n\u001b[0;32m     56\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\rohun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:1462\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[0;32m   1461\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1462\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1465\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_weights_only_unpickler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1466\u001b[0m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1467\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1468\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1469\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1470\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rohun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:1964\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1962\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[0;32m   1963\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m map_location\n\u001b[1;32m-> 1964\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1965\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1967\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n",
      "File \u001b[1;32mc:\\Users\\rohun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_weights_only_unpickler.py:512\u001b[0m, in \u001b[0;36mUnpickler.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;28mtype\u001b[39m(pid) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m\n\u001b[0;32m    506\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pid) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mserialization\u001b[38;5;241m.\u001b[39m_maybe_decode_ascii(pid[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    508\u001b[0m     ):\n\u001b[0;32m    509\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\n\u001b[0;32m    510\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly persistent_load of storage is allowed, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpid[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    511\u001b[0m         )\n\u001b[1;32m--> 512\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpersistent_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [BINGET[\u001b[38;5;241m0\u001b[39m], LONG_BINGET[\u001b[38;5;241m0\u001b[39m]]:\n\u001b[0;32m    514\u001b[0m     idx \u001b[38;5;241m=\u001b[39m (read(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m key[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m BINGET[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m unpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<I\u001b[39m\u001b[38;5;124m\"\u001b[39m, read(\u001b[38;5;241m4\u001b[39m)))[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\rohun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:1928\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[1;32m-> 1928\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1929\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1930\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1932\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[1;32mc:\\Users\\rohun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:1900\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[1;34m(dtype, numel, key, location)\u001b[0m\n\u001b[0;32m   1895\u001b[0m         storage\u001b[38;5;241m.\u001b[39mbyteswap(dtype)\n\u001b[0;32m   1897\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[0;32m   1898\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[0;32m   1899\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[1;32m-> 1900\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   1901\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1902\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1903\u001b[0m )\n\u001b[0;32m   1905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typed_storage\u001b[38;5;241m.\u001b[39m_data_ptr() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1906\u001b[0m     loaded_storages[key] \u001b[38;5;241m=\u001b[39m typed_storage\n",
      "File \u001b[1;32mc:\\Users\\rohun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:693\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    674\u001b[0m \u001b[38;5;124;03mRestores `storage` using a deserializer function registered for the `location`.\u001b[39;00m\n\u001b[0;32m    675\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;124;03m       all matching ones return `None`.\u001b[39;00m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    692\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[1;32m--> 693\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    694\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    695\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\rohun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:631\u001b[0m, in \u001b[0;36m_deserialize\u001b[1;34m(backend_name, obj, location)\u001b[0m\n\u001b[0;32m    629\u001b[0m     backend_name \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_privateuse1_backend_name()\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(backend_name):\n\u001b[1;32m--> 631\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\rohun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:600\u001b[0m, in \u001b[0;36m_validate_device\u001b[1;34m(location, backend_name)\u001b[0m\n\u001b[0;32m    598\u001b[0m     device_index \u001b[38;5;241m=\u001b[39m device\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;28;01mif\u001b[39;00m device\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(device_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_available\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m device_module\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m--> 600\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    601\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to deserialize object on a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    602\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice but torch.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.is_available() is False. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    603\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you are running on a CPU-only machine, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    604\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    605\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto map your storages to the CPU.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    606\u001b[0m     )\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(device_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice_count\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    608\u001b[0m     device_count \u001b[38;5;241m=\u001b[39m device_module\u001b[38;5;241m.\u001b[39mdevice_count()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "# Train and evaluate the model\n",
    "train(model, train_loader, val_loader, criterion, optimizer, num_epochs=100)\n",
    "evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will attempt to use Stochastic Gradient Descent (SGD) with momentum to try and optimize the neural network. This method of optimization updates the model’s weights using random subsets of data, making it more efficient than batch gradient descent. Adding momentum (set to 0.9) helps accelerate convergence by smoothing updates and reducing oscillations. We set the learning rate to 0.01 to control the step size in each update.\n",
    "\n",
    "Now, let's define the model, apply the optimizer, and test it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.2194\n",
      "Epoch [2/10], Loss: 0.2110\n",
      "Epoch [3/10], Loss: 0.2112\n",
      "Epoch [4/10], Loss: 0.2104\n",
      "Epoch [5/10], Loss: 0.2104\n",
      "Epoch [6/10], Loss: 0.2100\n",
      "Epoch [7/10], Loss: 0.2101\n",
      "Epoch [8/10], Loss: 0.2101\n",
      "Epoch [9/10], Loss: 0.2100\n",
      "Epoch [10/10], Loss: 0.2100\n",
      "Test Loss: 0.2117, Test Accuracy: 69.75%\n",
      "Test Accuracy after optimization: 69.75%, Test Loss: 0.2117\n"
     ]
    }
   ],
   "source": [
    "# instantiate the model (using the same parameters as before)\n",
    "input_size = 34\n",
    "hidden_size1 = 64\n",
    "hidden_size2 = 32\n",
    "output_size = 1\n",
    "\n",
    "model = NeuralNetwork(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# define loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# train the new model\n",
    "def train_model(model, train_loader, optimizer, criterion, epochs=10):\n",
    "    model.train() \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}')\n",
    "\n",
    "# test the model\n",
    "def test_model(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad(): \n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs).squeeze()\n",
    "            loss = criterion(outputs, labels) \n",
    "            total_loss += loss.item()\n",
    "\n",
    "            predictions = torch.round(outputs)  # round to nearest integer for classification\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    accuracy = correct / total * 100\n",
    "    print(f'Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "    return accuracy, avg_loss\n",
    "\n",
    "\n",
    "# train the model\n",
    "train_model(model, train_loader, optimizer, criterion, epochs=10)\n",
    "\n",
    "# test the model\n",
    "test_accuracy, test_loss = test_model(model, test_loader, criterion)\n",
    "print(f'Test Accuracy after optimization: {test_accuracy:.2f}%, Test Loss: {test_loss:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
